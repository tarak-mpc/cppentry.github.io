---
layout:     post
title:      Hadoop参数配置
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                <p>hadoop 参数配置</p>

<p><a class="tag" href="http://www.oschina.net/search?scope=blog&amp;q=hadoop" rel="nofollow">hadoop</a> <a class="tag" href="http://www.oschina.net/search?scope=blog&amp;q=%E5%8F%82%E6%95%B0" rel="nofollow">参数</a> <a class="tag" href="http://www.oschina.net/search?scope=blog&amp;q=hadoop%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0" rel="nofollow">hadoop配置参数</a> <a class="tag" href="http://www.oschina.net/search?scope=blog&amp;q=hadoop%E4%BC%98%E5%8C%96" rel="nofollow">hadoop优化</a></p>

<p> </p>

<p><span style="color:#ffffff;">目录[-]</span></p>

<p><a href="http://my.oschina.net/u/1378204/blog/471338?fromerr=bN5IEJif#OSC_h1_1" rel="nofollow">Hadoop参数汇总</a><a href="http://my.oschina.net/u/1378204/blog/471338?fromerr=bN5IEJif#OSC_h2_2" rel="nofollow">linux参数</a><a href="http://my.oschina.net/u/1378204/blog/471338?fromerr=bN5IEJif#OSC_h2_3" rel="nofollow">JVM参数</a><a href="http://my.oschina.net/u/1378204/blog/471338?fromerr=bN5IEJif#OSC_h2_4" rel="nofollow">Hadoop参数大全</a><a href="http://my.oschina.net/u/1378204/blog/471338?fromerr=bN5IEJif#OSC_h3_5" rel="nofollow">core-default.xml</a><a href="http://my.oschina.net/u/1378204/blog/471338?fromerr=bN5IEJif#OSC_h3_6" rel="nofollow">hdfs-default.xml</a><a href="http://my.oschina.net/u/1378204/blog/471338?fromerr=bN5IEJif#OSC_h3_7" rel="nofollow">yarn-default.xml</a></p>

<h1>Hadoop参数汇总</h1>

<p>@(hadoop)[配置]</p>

<h2>linux参数</h2>

<p>以下参数最好优化一下：</p>

<ol style="margin-left:20px;"><li>文件描述符ulimit -n</li>
	<li>用户最大进程 nproc （hbase需要 hbse book）</li>
	<li>关闭swap分区</li>
	<li>设置合理的预读取缓冲区</li>
	<li>Linux的内核的IO调度器</li>
</ol><h2>JVM参数</h2>

<p>JVM方面的优化项<a href="http://developer.amd.com/wordpress/media/2012/10/Hadoop_Tuning_Guide-Version5.pdf" rel="nofollow">Hadoop Performance Tuning Guide</a></p>

<h2>Hadoop参数大全</h2>

<pre class="has">
<code class="language-hljs">适用版本：4.3.0</code></pre>

<p>主要配置文件：</p>

<ul style="margin-left:20px;"><li style="margin-left:0px;"><a>core</a></li>
	<li style="margin-left:0px;"><a>hdfs</a></li>
	<li style="margin-left:0px;"><a>yarn</a></li>
	<li style="margin-left:0px;"><a>mapred</a></li>
</ul><p>重要性表示如下：</p>

<ul style="margin-left:20px;"><li style="margin-left:0px;"><strong>重要</strong></li>
	<li style="margin-left:0px;">一般</li>
	<li style="margin-left:0px;">不重要</li>
</ul><h3><a>core-default.xml</a></h3>

<ul style="margin-left:20px;"><li style="margin-left:0px;">
	<p>hadoop.common.configuration.version</p>

	<blockquote>
	<p>配置文件的版本。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>hadoop.tmp.dir=/tmp/hadoop-${user.name}</strong></p>

	<blockquote>
	<p>Hadoop的临时目录，其它目录会基于此路径。本地目录。</p>

	<blockquote>
	<p><strong>只可以设置一个值；建议设置到一个足够空间的地方，而不是默认的/tmp下</strong><br>
	服务端参数，修改需重启</p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>hadoop.security.authorization=false</strong></p>

	<blockquote>
	<p>是否开启安全服务验证。</p>

	<blockquote>
	<p><strong>建议不开启。认证操作比较复杂，在公司内部网络下，重要性没那么高</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>io.file.buffer.size=4096</strong></p>

	<blockquote>
	<p>在读写文件时使用的缓存大小。这个大小应该是内存Page的倍数。</p>

	<blockquote>
	<p><strong>建议1M</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>io.compression.codecs=null</strong></p>

	<blockquote>
	<p>压缩和解压缩编码类列表，用逗号分隔。这些类是使用Java ServiceLoader加载。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>fs.defaultFS=file:///</strong></p>

	<blockquote>
	<p>默认文件系统的名称。URI形式。uri's的scheme需要由(fs.SCHEME.impl)指定文件系统实现类。 uri's的authority部分用来指定host, port等。默认是本地文件系统。</p>

	<blockquote>
	<p><strong>HA方式，这里设置服务名，例如：hdfs://mycluster1</strong><br>
	HDFS的客户端访问HDFS需要此参数。</p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>fs.trash.interval=0</strong></p>

	<blockquote>
	<p>以分钟为单位的垃圾回收时间，垃圾站中数据超过此时间，会被删除。如果是0，垃圾回收机制关闭。可以配置在服务器端和客户端。如果在服务器端配置trash无效，会检查客户端配置。如果服务器端配置有效，客户端配置会忽略。</p>

	<blockquote>
	<p><strong>建议开启，建议4320（3天）</strong><br>
	垃圾回收站，如有同名文件被删除，会给文件顺序编号，例如：a.txt,a.txt(1)</p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>fs.trash.checkpoint.interval=0</strong></p>

	<blockquote>
	<p>以分钟为单位的垃圾回收检查间隔。应该小于或等于fs.trash.interval。如果是0，值等同于fs.trash.interval。每次检查器运行，会创建新的检查点。</p>

	<blockquote>
	<p><strong>建议设置为60（1小时）</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.ha.fencing.methods=null</strong></p>

	<blockquote>
	<p>HDFS的HA功能的防脑裂方法。可以是内建的方法(例如shell和sshfence)或者用户定义的方法。建议使用sshfence(hadoop:9922)，括号内的是用户名和端口，注意，这需要NN的2台机器之间能够免密码登陆</p>
	</blockquote>

	<blockquote>
	<p>fences是防止脑裂的方法，保证NN中仅一个是Active的，如果2者都是Active的，新的会把旧的强制Kill。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.ha.fencing.ssh.private-key-files=null</strong></p>

	<blockquote>
	<p>使用sshfence时，SSH的私钥文件。 <strong>使用了sshfence，这个必须指定</strong></p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>ha.zookeeper.quorum=null</strong></p>

	<blockquote>
	<p>Ha功能，需要一组zk地址，用逗号分隔。被ZKFailoverController使用于自动失效备援failover。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>ha.zookeeper.session-timeout.ms=5000</strong></p>

	<blockquote>
	<p>ZK连接超时。ZKFC连接ZK时用。设置一个小值可以更快的探测到服务器崩溃（crash),但也会更频繁的触发失效备援，在传输错误或者网络不畅时。<strong>建议10s-30s</strong></p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>hadoop.http.staticuser.user=dr.who</strong></p>

	<blockquote>
	<p>在网页界面访问数据使用的用户名。默认值是一个不真实存在的用户，此用户权限很小，不能访问不同用户的数据。这保证了数据安全。也可以设置为hdfs和hadoop等具有较高权限的用户，但会导致能够登陆网页界面的人能看到其它用户数据。实际设置请综合考虑。如无特殊需求。使用默认值就好</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>fs.permissions.umask-mode=22</strong></p>

	<blockquote>
	<p>在创建文件和目录时使用此umask值（用户掩码）。类linux上的文件权限掩码。可以使用8进制数字也可以使用符号，例如："022" (8进制，等同于以符号表示的u=rwx,g=r-x,o=r-x)，或者"u=rwx,g=rwx,o="(符号法，等同于8进制的007)。注意，8进制的掩码，和实际权限设置值正好相反，建议使用符号表示法，描述更清晰</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.native.lib.available=true</p>

	<blockquote>
	<p>是否启动Hadoop的本地库，默认启用。本地库可以加快基本操作，例如IO，压缩等。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.http.filter.initializers=org.apache.hadoop.http.lib.StaticUserWebFilter</p>

	<blockquote>
	<p>Hadoop的Http服务中，用逗号分隔的一组过滤器类名，每个类必须扩展自org.apache.hadoop.http.FilterInitializer。 这些组件被初始化，应用于全部用户的JSP和Servlet页面。 列表中定义的顺序就是过滤器被调用的顺序。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.security.authentication</p>

	<blockquote>
	<p>安全验证规则，可以是simple和kerberos。simple意味着不验证。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.security.group.mapping=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback</p>

	<blockquote>
	<p>user到group的映射类。ACL用它以给定user获取group。默认实现是 org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback, 如果JNI有效，它将发挥作用，使用Hadoop的API去获取user的groups列表。如果JNI无效，会使用另一个基于shell的实现, ShellBasedUnixGroupsMapping。这个实现是基于Linux、Unix的shell的环境。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.security.groups.cache.secs=300</p>

	<blockquote>
	<p>user到gourp映射缓存的有效时间。如果超时，会再次调用去获取新的映射关系然后缓存起来。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.security.service.user.name.key=null</p>

	<blockquote>
	<p>如果相同的RPC协议被多个Server实现，这个配置是用来指定在客户端进行RPC调用时，使用哪个principal name去联系服务器。不建议使用</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.security.uid.cache.secs=14400</p>

	<blockquote>
	<p>安全选项。不建议使用</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.rpc.protection=authentication</p>

	<blockquote>
	<p>rpc连接保护。可取的值有authentication（认证）, integrity（完整） and privacy（隐私）。不建议使用</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.work.around.non.threadsafe.getpwuid=false</p>

	<blockquote>
	<p>一些系统已知在调用getpwuid_r和getpwgid_r有问题，这些调用是非线程安全的。这个问题的主要表现特征是JVM崩溃。如果你的系统有这些问题，开启这个选项。默认是关闭的。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.kerberos.kinit.command=kinit</p>

	<blockquote>
	<p>用来定期的向Hadoop提供新的Kerberos证书。所提供命令需要能够在运行Hadoop客户端的用户路径中查找到，否则，请指定绝对路径。不建议使用</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.security.auth_to_local=null</p>

	<blockquote>
	<p>映射kerberos principals（代理人）到本地用户名</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.bytes.per.checksum=512</p>

	<blockquote>
	<p>每次进行校验和检查的字节数。一定不能大于io.file.buffer.size.</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.skip.checksum.errors=FALSE</p>

	<blockquote>
	<p>是否跳过校验和错误，默认是否，校验和异常时会抛出错误。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.serializations=org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization</p>

	<blockquote>
	<p>序列化类列表，可以被用来获取序列化器和反序列化器（serializers and deserializers）。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.seqfile.local.dir=${hadoop.tmp.dir}/io/local</p>

	<blockquote>
	<p>本地文件目录。sequence file在merge过程中存储内部数据的地方。可以是逗号分隔的一组目录。最好在不同磁盘以分散IO。实际不存在的目录会被忽略。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.map.index.skip=0</p>

	<blockquote>
	<p>跳过的索引实体数量在entry之间。默认是0。设置大于0的值可以用更少的内存打开大MapFiles。<strong>注意：MpaFile是一组Sequence文件，是排序后的，带内部索引的文件</strong></p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.map.index.interval=128</p>

	<blockquote>
	<p>MapFile包含两个文件，数据文件和索引文件。每io.map.index.interval个记录写入数据文件，一条记录(行key，数据文件位置)写入索引文件。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.default.name=file:///</p>

	<blockquote>
	<p><strong>过时</strong>。使用(fs.defaultFS)代替</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.AbstractFileSystem.file.impl=org.apache.hadoop.fs.local.LocalFs</p>

	<blockquote>
	<p>文件系统实现类：file</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.AbstractFileSystem.hdfs.impl=org.apache.hadoop.fs.Hdfs</p>

	<blockquote>
	<p>文件系统实现类：hdfs</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.AbstractFileSystem.viewfs.impl=org.apache.hadoop.fs.viewfs.ViewFs</p>

	<blockquote>
	<p>文件系统实现类：viewfs (例如客户端挂载表)。</p>

	<blockquote>
	<p><strong>在实现federation特性时，客户端可以部署此系统，方便同时访问多个nameservice</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.ftp.host=0.0.0.0</p>

	<blockquote>
	<p>非Hdfs文件系统设置。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.ftp.host.port=21</p>

	<blockquote>
	<p>非Hdfs文件系统设置。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.df.interval=60000</p>

	<blockquote>
	<p>磁盘使用统计刷新间隔，以毫秒为单位</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.s3.block.size=67108864</p>

	<blockquote>
	<p>非Hdfs文件系统设置。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.s3.buffer.dir=${hadoop.tmp.dir}/s3</p>

	<blockquote>
	<p>非Hdfs文件系统设置。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.s3.maxRetries=4</p>

	<blockquote>
	<p>非Hdfs文件系统设置。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.s3.sleepTimeSeconds=10</p>

	<blockquote>
	<p>非Hdfs文件系统设置。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.automatic.close=true</p>

	<blockquote>
	<p>默认的，文件系统实例在程序退出时自动关闭，通过JVM shutdown hook方式。可以把此属性设置为false取消这种操作。这是一个高级选项，需要使用者特别关注关闭顺序。不要关闭</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>fs.s3n.block.size=67108864</p>

	<blockquote>
	<p>非Hdfs文件系统设置。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.seqfile.compress.blocksize=1000000</p>

	<blockquote>
	<p>SequenceFiles以块压缩方式压缩时，块大小大于此值时才启动压缩。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.seqfile.lazydecompress=TRUE</p>

	<blockquote>
	<p>懒惰解压，仅在必要时解压，仅对块压缩的SequenceFiles有效。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.seqfile.sorter.recordlimit=1000000</p>

	<blockquote>
	<p>在SequenceFiles.Sorter spill过程中，保存在内存中的记录数</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.mapfile.bloom.size=1048576</p>

	<blockquote>
	<p>在BloomMapFile使用的布隆过滤器内存大小。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>io.mapfile.bloom.error.rate=0.005</p>

	<blockquote>
	<p>BloomMapFile中使用布隆过滤器失败比率. 如果减少这个值，使用的内存会成指数增长。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.util.hash.type=murmur</p>

	<blockquote>
	<p>默认Hash算法实现. 'murmur':MurmurHash, 'jenkins':JenkinsHash.</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ipc.client.idlethreshold=4000</p>

	<blockquote>
	<p>连接数阀值，超过此值，需要进行空闲连接检查</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ipc.client.kill.max=10</p>

	<blockquote>
	<p>定义客户端最大数量，超过会被断开连接</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ipc.client.connection.maxidletime=10000</p>

	<blockquote>
	<p>毫秒，最大时间，超过后客户端会断开和服务器的连接。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ipc.client.connect.max.retries=10</p>

	<blockquote>
	<p>客户端连接重试次数。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ipc.client.connect.max.retries.on.timeouts=45</p>

	<blockquote>
	<p>在连接超时后，客户端连接重试次数</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ipc.server.listen.queue.size=128</p>

	<blockquote>
	<p>定义服务器端接收客户端连接的监听队列长度</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ipc.server.tcpnodelay=false</p>

	<blockquote>
	<p>在服务器端开启/关闭Nagle's算法，此算法可以延迟小数据包发送，从而达到网络流量更有效利用。但是这对小数据包是不利的。默认关闭。建议false，即开启Nagle算法</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ipc.client.tcpnodelay=false</p>

	<blockquote>
	<p>参考ipc.server.tcpnodelay，客户端参数。或许可以考虑关闭Nagle算法，增加客户端响应速度</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory</p>

	<blockquote>
	<p>高级选项，暂不考虑</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.rpc.socket.factory.class.ClientProtocol=null</p>

	<blockquote>
	<p>高级选项，暂不考虑</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.socks.server=null</p>

	<blockquote>
	<p>高级选项，暂不考虑</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>net.topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping</p>

	<blockquote>
	<p>机架感知实现类。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>net.topology.script.file.name=null</p>

	<blockquote>
	<p>配合ScriptBasedMapping使用。脚本文件。此脚本文件，输入是ip地址，输出是机架路径。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>net.topology.script.number.args=100</p>

	<blockquote>
	<p>机架感知脚本文件的参数最大数量。脚本每次运行被传递的参数，每个参数是一个ip地址</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>net.topology.table.file.name=null</p>

	<blockquote>
	<p>在net.topology.script.file.name被设置为 org.apache.hadoop.net.TableMapping时，可以使用此配置。文件格式是一个有两个列的文本文件，使用空白字符分隔。第一列是DNS或IP地址，第二列是机架路径。如无指定，使用默认机架（/default-rack）</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>file.stream-buffer-size=4096</p>

	<blockquote>
	<p>非hdfs文件系统，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>s3.stream-buffer-size=4096</p>

	<blockquote>
	<p>非hdfs文件系统，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>kfs.stream-buffer-size=4096</p>

	<blockquote>
	<p>非hdfs文件系统，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ftp.stream-buffer-size=4096</p>

	<blockquote>
	<p>非hdfs文件系统，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>tfile.io.chunk.size=1048576</p>

	<blockquote>
	<p>非hdfs文件系统，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.http.authentication.type=simple</p>

	<blockquote>
	<p>Oozie Http终端安全验证。可选值：simple | kerberos |#AUTHENTICATION_HANDLER_CLASSNAME#</p>

	<blockquote>
	<p><strong>建议simple，关闭验证</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.http.authentication.token.validity=36000</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.http.authentication.signature.secret.file=${user.home}/hadoop-http-auth-signature-secret</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.http.authentication.cookie.domain=null</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.http.authentication.simple.anonymous.allowed=TRUE</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.http.authentication.kerberos.principal=HTTP/_HOST<a class="referer" href="http://my.oschina.net/u/570656" rel="nofollow">@LOCALHOST</a></p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.http.authentication.kerberos.keytab=${user.home}/hadoop.keytab</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.ha.fencing.ssh.connect-timeout=30000</p>

	<blockquote>
	<p>SSH连接超时，毫秒，仅适用于内建的sshfence fencer。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.zookeeper.parent-znode=/hadoop-ha</p>

	<blockquote>
	<p>ZK失效备援功能，需要在ZK上创建节点，这里是根节点的名称。ZKFC会在这下面工作。注意，NameService ID会 被写到此节点下，所以即便是开启federation功能，也仅需要指定一个值。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.zookeeper.acl=world:anyone:rwcda</p>

	<blockquote>
	<p>ZKFC创建的ZK节点的访问控制权限设置。可以多个，逗号分隔。此设置和ZK的CLI使用相同的格式。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.zookeeper.auth=null</p>

	<blockquote>
	<p>ZK操作时的权限验证。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.ssl.keystores.factory.class=org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.ssl.require.client.cert=FALSE</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.ssl.hostname.verifier=DEFAULT</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.ssl.server.conf=ssl-server.xml</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.ssl.client.conf=ssl-client.xml</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.ssl.enabled=FALSE</p>

	<blockquote>
	<p>安全选项。暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.jetty.logs.serve.aliases=TRUE</p>

	<blockquote>
	<p>是否允许在Jetty中使用别名服务。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.health-monitor.connect-retry-interval.ms=1000</p>

	<blockquote>
	<p>HA功能的健康监控连接重试间隔</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.health-monitor.check-interval.ms=1000</p>

	<blockquote>
	<p>HA功能的健康监控连接间隔</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.health-monitor.sleep-after-disconnect.ms=1000</p>

	<blockquote>
	<p>HA功能的健康监控，在因网络问题失去连接后休眠多久。用于避免立即重试，此时网络问题仍在，没有意义</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.health-monitor.rpc-timeout.ms=45000</p>

	<blockquote>
	<p>HA功能健康监控的超时时间，毫秒</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.failover-controller.new-active.rpc-timeout.ms=60000</p>

	<blockquote>
	<p>FC等待新的NN变成active状态的超时时间。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.failover-controller.graceful-fence.rpc-timeout.ms=5000</p>

	<blockquote>
	<p>FC等待旧的active变成standby的超时时间。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.failover-controller.graceful-fence.connection.retries=1</p>

	<blockquote>
	<p>FC在做完美隔离是的连接重试次数（graceful fencing）</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>ha.failover-controller.cli-check.rpc-timeout.ms=20000</p>

	<blockquote>
	<p>手动运行的FC功能（从CLI）等待健康检查、服务状态的超时时间。</p>
	</blockquote>
	</li>
</ul><h3><a>hdfs-default.xml</a></h3>

<ul style="margin-left:20px;"><li style="margin-left:0px;">
	<p>hadoop.hdfs.configuration.version=1</p>

	<p>配置文件的版本</p>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.datanode.address=0.0.0.0:50010</strong></p>

	<p>DN服务地址和端口，用于数据传输。0表示任意空闲端口。</p>

	<pre class="has">
<code class="language-hljs">xferPort dfs.datanode.address <span style="color:#2aa198;">50010</span> 数据流地址   数据传输 <span style="color:#268bd2;">info</span>Port    dfs.datanode.http.address <span style="color:#2aa198;">50075</span> ipcPort     dfs.datanode.ipc.address <span style="color:#2aa198;">50020</span> 命令</code> dfs.datanode.address <span style="color:#2aa198;">50010</span> 数据流地址   数据传输 <span style="color:#268bd2;">info</span>Port    dfs.datanode.http.address <span style="color:#2aa198;">50075</span> ipcPort     dfs.datanode.ipc.address <span style="color:#2aa198;">50020</span> 命令</pre>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.datanode.http.address=0.0.0.0:50075</strong></p>

	<blockquote>
	<p>DN的HTTP服务地址和端口。0表示任意空闲端口。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.datanode.ipc.address=0.0.0.0:50020</strong></p>

	<blockquote>
	<p>DN的IPC地址和端口。0表示任意空闲端口。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.rpc-address=0.0.0.0:50090</strong></p>

	<blockquote>
	<p>NN的RPC地址和端口</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.http-address=0.0.0.0:50070</strong></p>

	<blockquote>
	<p>NN的HTTP地址和端口。0表示任意空闲端口。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.datanode.du.reserved=0</strong></p>

	<blockquote>
	<p>每个磁盘（volume）的保留空间，字节。要注意留足够的空间给非HDFS文件使用。建议保留磁盘容量的5%或者50G以上</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.name.dir.restore=FALSE</strong></p>

	<blockquote>
	<p>设置为true，允许NN尝试恢复之前失败的dfs.namenode.name.dir目录。在创建checkpoint是做此尝试。如果设置多个磁盘，建议允许</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.edits.dir=${dfs.namenode.name.dir}</strong></p>

	<blockquote>
	<p>本地文件，NN存放edits文件的目录。可以是逗号分隔的目录列表。edits文件会存储在每个目录，冗余安全。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.shared.edits.dir=null</strong></p>

	<blockquote>
	<p>在多个NN中共享存储目录，用于存放edits文件。这个目录，由active写，由standby读，以保持命名空间数据一致。此目录不需要是dfs.namenode.edits.dir中列出的。在非HA集群中，它不会使用。建议使用qj方式，可以不关注这个选项</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.edits.journal-plugin.qjournal=org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager</strong></p>

	<blockquote>
	<p>qj方式共享edits。建议使用此方式</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.permissions.enabled=true</strong></p>

	<blockquote>
	<p>是否在HDFS中开启权限检查。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.permissions.superusergroup=supergroup</strong></p>

	<blockquote>
	<p>超级用户组。仅能设置一个。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.datanode.data.dir=file://${hadoop.tmp.dir}/dfs/data</strong></p>

	<blockquote>
	<p>本地磁盘目录，HDFS数据应该存储Block的地方。可以是逗号分隔的目录列表（典型的，每个目录在不同的磁盘）。这些目录被轮流使用，一个块存储在这个目录，下一个块存储在下一个目录，依次循环。每个块在同一个机器上仅存储一份。不存在的目录被忽略。必须创建文件夹，否则被视为不存在。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.replication=3</strong></p>

	<blockquote>
	<p>数据块副本数。此值可以在创建文件是设定，客户端可以只有设定，也可以在命令行修改。不同文件可以有不同的副本数。默认值用于未指定时。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.replication.max=512</strong></p>

	<blockquote>
	<p>最大块副本数，不要大于节点总数。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.replication.min=1</strong></p>

	<blockquote>
	<p>最小块副本数。在上传文件时，达到最小副本数，就认为上传是成功的</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.blocksize=67108864</strong></p>

	<blockquote>
	<p>块大小，字节。可以使用后缀: k(kilo), m(mega), g(giga), t(tera), p(peta), e(exa)指定大小 (就像128k, 512m, 1g, 等待)。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.client.block.write.retries=3</strong></p>

	<blockquote>
	<p>客户端写数据到DN时，最大重试次数。超过重试次数就会报出错误。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.client.block.write.replace-datanode-on-failure.enable=true</strong></p>

	<blockquote>
	<p>在进行pipeline写数据（上传数据的方式）时，如果DN或者磁盘故障，客户端将尝试移除失败的DN，然后写到剩下的磁盘。一个结果是，pipeline中的DN减少了。这个特性是添加新的DN到pipeline。这是一个站点范围的选项。当集群规模非常小时，例如3个或者更小，集群管理者可能想要禁止掉此特性。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.client.block.write.replace-datanode-on-failure.policy=DEFAULT</strong></p>

	<blockquote>
	<p>此属性仅在dfs.client.block.write.replace-datanode-on-failure.enable设置为true时有效。</p>
	</blockquote>

	<blockquote>
	<ul style="margin-left:20px;"><li style="margin-left:0px;">ALWAYS: 总是添加新的DN
		<ul style="margin-left:20px;"><li style="margin-left:0px;">NEVER: 从不添加新的DN</li>
			<li style="margin-left:0px;">DEFAULT: 设r是副本数，n是要写的DN数。在r&gt;=3并且floor(r/2)&gt;=n或者r&gt;n(前提是文件是hflushed/appended)时添加新的DN。</li>
		</ul></li>
	</ul></blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.heartbeat.interval=3</strong></p>

	<blockquote>
	<p>DN的心跳间隔，秒</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.handler.count=10</strong></p>

	<blockquote>
	<p>NN的服务线程数。用于处理RPC请求。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.safemode.threshold-pct=0.999f</strong></p>

	<blockquote>
	<p>数据进入安全模式阀值，百分比，float形式，数据块达到最小副本数（dfs.namenode.replication.min）的百分比。值小于等于0意味着在退出安全模式前不等待数据修复。大于1的值将导致无法离开安全模式。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.safemode.extension=30000</strong></p>

	<blockquote>
	<p>安全模式扩展存在时间，在需要的阀值达到后，毫秒。可以设置为0，或者比较短的一个时间，例如3秒</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.datanode.balance.bandwidthPerSec=1048576</strong></p>

	<blockquote>
	<p>在做数据平衡时，每个DN最大带宽占用，每秒字节。默认值是1M。建议可以到10M</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.hosts=null</strong></p>

	<blockquote>
	<p>文件名，包含了一个host列表，允许列表内机器连到NN。必须指定完整路径。如果值为空，全部hosts都允许连入。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.hosts.exclude=null</strong></p>

	<blockquote>
	<p>文件名，包含了一个hosts列表，不允许列表内机器连到NN。必须指定完整路径。如果值为空。没有host被禁止。如果上述2个都设置并且有重合，dfs.hosts中优先级高。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.stream-buffer-size=4096</strong></p>

	<blockquote>
	<p>文件流缓存大小。需要是硬件page大小的整数倍。在读写操作时，数据缓存大小。注意和core-default.xml中指定文件类型的缓存是不同的，这个是dfs共用的</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.num.extra.edits.retained=1000000</strong></p>

	<blockquote>
	<p>除最小的必须的editlog之外，额外保留的editlog文件数量。这是有用的，可以用于审核目的，或者HA设置一个远程Standby节点并且有时可能离线时，都需要保留一个较长的backlog。</p>

	<hr><p>典型的，每个edit大约几百字节，默认的1百万editlog大约有百兆到1G。注意：早先的extra edits文件可能操作这里设置的值，因为还有其它选项，例如dfs.namenode.max.extra.edits.segments.retained</p>

	<blockquote>
	<p><strong>建议值：2200，约3天的</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.datanode.handler.count=10</strong></p>

	<blockquote>
	<p>DN的服务线程数。这些线程仅用于接收请求，处理业务命令</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.datanode.failed.volumes.tolerated=0</strong></p>

	<blockquote>
	<p>可以接受的卷的失败数量。默认值0表示，任一个卷失败都会导致DN关闭。</p>

	<blockquote>
	<p><strong>建议设置此值，避免个别磁盘问题。如果此值超过真实磁盘数，将会报错，启动失败</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.support.allow.format=true</strong></p>

	<blockquote>
	<p>NN是否允许被格式化？在生产系统，把它设置为false，阻止任何格式化操作在一个运行的DFS上。</p>

	<blockquote>
	<p><strong>建议初次格式化后，修改配置禁止</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.client.failover.max.attempts=15</strong></p>

	<blockquote>
	<p>专家设置。客户端失败重试次数。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.client.failover.connection.retries=0</strong></p>

	<blockquote>
	<p>专家设置。IPC客户端失败重试次数。在网络不稳定时建议加大此值</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.client.failover.connection.retries.on.timeouts=0</strong></p>

	<blockquote>
	<p>专家设置。IPC客户端失败重试次数，此失败仅指超时失败。在网络不稳定时建议加大此值</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.nameservices=null</strong></p>

	<blockquote>
	<p>nameservices列表。逗号分隔。</p>

	<blockquote>
	<p><strong>我们常用的仅配置一个，启动federation功能需要配置多个</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.nameservice.id=null</strong></p>

	<blockquote>
	<p>nameservice id，如果没有配置或者配置多个，由匹配到的本地节点地址配置的IP地址决定。我们进配置一个NS的情况下，建议这里不配置</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.ha.namenodes.EXAMPLENAMESERVICE=null</strong></p>

	<blockquote>
	<p>包含一个NN列表。EXAMPLENAMESERVICE是指具体的nameservice名称，通常就是dfs.nameservices中配置的。值是预备配置的NN的ID。</p>

	<blockquote>
	<p><strong>ID是自己取的，不重复就可以，例如nn1,nn2</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.ha.namenode.id=null</strong></p>

	<blockquote>
	<p>NN的ID，如果没有配置，由系统决定。通过匹配本地节点地址和配置的地址。</p>

	<blockquote>
	<p><strong>这里设置的是本机的NN的ID（此配置仅对NN生效），由于要配置2个NN，建议没有特殊需要，这里不进行配置</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.ha.automatic-failover.enabled=FALSE</strong></p>

	<blockquote>
	<p>是否开启自动故障转移。建议开启，true</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.avoid.write.stale.datanode=FALSE</strong></p>

	<blockquote>
	<p>决定是否避开在脏DN上写数据。写操作将会避开脏DN，除非超过一个配置的比率 (dfs.namenode.write.stale.datanode.ratio)。</p>

	<blockquote>
	<p><strong>尝试开启</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.journalnode.rpc-address=0.0.0.0:8485</strong></p>

	<blockquote>
	<p>JournalNode RPC服务地址和端口</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.journalnode.http-address=0.0.0.0:8480</strong></p>

	<blockquote>
	<p>JournalNode的HTTP地址和端口。端口设置为0表示随机选择。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>dfs.namenode.audit.loggers=default</strong></p>

	<blockquote>
	<p>审查日志的实现类列表，能够接收audit事件。它们需要实现 org.apache.hadoop.hdfs.server.namenode.AuditLogger接口。默认值"default"可以用于引用默认的audit logger， 它使用配置的日志系统。安装客户自己的audit loggers可能影响NN的稳定性和性能。</p>

	<blockquote>
	<p><strong>建议default，开启</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client.socket-timeout=60*1000</p>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.socket.write.timeout=8*60*1000</p>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.socket.reuse.keepalive=1000</p>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.logging.level=info</p>

	<blockquote>
	<p>DFS的NN的日志等级。值可以是：info，dir(跟踪命名空间变动)，"block" (跟踪块的创建删除，replication变动)，或者"all".</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.secondary.http-address=0.0.0.0:50090</p>

	<blockquote>
	<p>SNN的http服务地址。如果是0，服务将随机选择一个空闲端口。使用了HA后，就不再使用SNN了</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.https.enable=FALSE</p>

	<blockquote>
	<p>允许HDFS支持HTTPS(SSL)。建议不支持</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client.https.need-auth=FALSE</p>

	<blockquote>
	<p>安全选项，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.https.server.keystore.resource=ssl-server.xml</p>

	<blockquote>
	<p>安全选项，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client.https.keystore.resource=ssl-client.xml</p>

	<blockquote>
	<p>安全选项，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.https.address=0.0.0.0:50475</p>

	<blockquote>
	<p>安全选项，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.https-address=0.0.0.0:50470</p>

	<blockquote>
	<p>安全选项，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.dns.interface=default</p>

	<blockquote>
	<p>DN汇报它的IP地址的网卡。我们给DN指定了0.0.0.0之类的地址，这个地址需要被解析成对外地址，这里指定的是网卡名，即那个网卡上绑定的IP是可以对外的IP，一般的，默认值就足够了</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.dns.nameserver=default</p>

	<blockquote>
	<p>DNS的域名或者IP地址。DN用它来确定自己的域名，在对外联系和显示时调用。一般的，默认值就足够了</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.backup.address=0.0.0.0:50100</p>

	<blockquote>
	<p>NN的BK节点地址和端口，0表示随机选用。使用HA，就不需要关注此选项了。建议不使用BK节点</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.backup.http-address=0.0.0.0:50105</p>

	<blockquote>
	<p>使用HA，就不需要关注此选项了。建议不使用BK节点</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.replication.considerLoad=true</p>

	<blockquote>
	<p>设定在选择存放目标时是否考虑负载。需要</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.default.chunk.view.size=32768</p>

	<blockquote>
	<p>在浏览器中查看一个文件时，可以看到的字节数。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.name.dir=file://${hadoop.tmp.dir}/dfs/name</p>

	<blockquote>
	<p>本地磁盘目录，NN存储fsimage文件的地方。可以是按逗号分隔的目录列表，fsimage文件会存储在全部目录，冗余安全。这里多个目录设定，最好在多个磁盘，另外，如果其中一个磁盘故障，不会导致系统故障，会跳过坏磁盘。由于使用了HA，建议仅设置一个。如果特别在意安全，可以设置2个</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.fs-limits.max-component-length=0</p>

	<blockquote>
	<p>路径中每个部分的最大字节长度（目录名，文件名的长度）。0表示不检查长度。长文件名影响性能</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.fs-limits.max-directory-items=0</p>

	<blockquote>
	<p>设置每个目录最多拥有多少个子目录或者文件。0表示无限制。同一目录下子文件和目录多影响性能</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.fs-limits.min-block-size=1048576</p>

	<blockquote>
	<p>最小的Block大小，字节。在NN创建时强制验证。避免用户设定过小的Block Size，导致过多的Block，这非常影响性能。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.fs-limits.max-blocks-per-file=1048576</p>

	<blockquote>
	<p>每个文件最大的Block数。在NN写时强制检查。用于防止创建超大文件。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.block.access.token.enable=FALSE</p>

	<blockquote>
	<p>访问DN时是否验证访问令牌。建议false，不检查</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.block.access.key.update.interval=600</p>

	<blockquote>
	<p>安全选项，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.block.access.token.lifetime=600</p>

	<blockquote>
	<p>安全选项，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.data.dir.perm=700</p>

	<blockquote>
	<p>本地数据目录权限设定。8进制或者符号方式都可以。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.blockreport.intervalMsec=21600000</p>

	<blockquote>
	<p>数据块汇报间隔，毫秒，默认是6小时。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.blockreport.initialDelay=0</p>

	<blockquote>
	<p>第一次数据块汇报时延迟，秒。目的是减轻NN压力？</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.directoryscan.interval=21600</p>

	<blockquote>
	<p>DN的数据块扫描间隔，秒。磁盘上数据和内存中数据调整一致。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.directoryscan.threads=1</p>

	<blockquote>
	<p>线程池要有多少线程用来并发的压缩磁盘的汇报数据。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.safemode.min.datanodes=0</p>

	<blockquote>
	<p>NN收到回报的DN的数量的最小值，达不到此值，NN不退出安全模式。（在系统启动时发生作用）。&lt;=0的值表示不关心DN数量，在启动时。大于DN实际数量的值会导致无法离开安全模式。建议不设置此值</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.max.objects=0</p>

	<blockquote>
	<p>DFS支持的最大文件、目录、数据块数量。0无限制。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.decommission.interval=30</p>

	<blockquote>
	<p>NN周期性检查退役是否完成的间隔，秒。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.decommission.nodes.per.interval=5</p>

	<blockquote>
	<p>NN检查退役是否完成，每dfs.namenode.decommission.interval秒检查的节点数量。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.replication.interval=3</p>

	<blockquote>
	<p>NN周期性计算DN的副本情况的频率，秒。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.accesstime.precision=3600000</p>

	<blockquote>
	<p>HDFS文件的访问时间精确到此值，默认是1小时。0表示禁用访问时间。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.plugins=null</p>

	<blockquote>
	<p>DN上的插件列表，逗号分隔。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.plugins=null</p>

	<blockquote>
	<p>NN上的插件列表，逗号分隔。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.bytes-per-checksum=512</p>

	<blockquote>
	<p>每次计算校验和的字节数。一定不能大于dfs.stream-buffer-size。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client-write-packet-size=65536</p>

	<blockquote>
	<p>客户端写数据时的包的大小。包是块中的更小单位数据集合</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client.write.exclude.nodes.cache.expiry.interval.millis=600000</p>

	<blockquote>
	<p>最大周期去让DN保持在例外节点队列中。毫秒。操过此周期，先前被排除的DN将被移除缓存并被尝试再次申请Block。默认为10分钟。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary</p>

	<blockquote>
	<p>本地文件系统中，DFS SNN应该在哪里存放临时[用于合并|合并后]（to merge）的Image。如果是逗号分隔的目录列表，Image文件存放多份。冗余备份。建议不使用SNN功能，忽略此配置</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir}</p>

	<blockquote>
	<p>建议不使用SNN功能，忽略此配置</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.checkpoint.period=3600</p>

	<blockquote>
	<p>建议不使用SNN功能，忽略此配置</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.checkpoint.txns=1000000</p>

	<blockquote>
	<p>建议不使用SNN功能，忽略此配置</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.checkpoint.check.period=60</p>

	<blockquote>
	<p>建议不使用SNN功能，忽略此配置</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.checkpoint.max-retries=3</p>

	<blockquote>
	<p>建议不使用SNN功能，忽略此配置</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.num.checkpoints.retained=2<br>
	建议不使用SNN功能，忽略此配置</p>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.num.extra.edits.retained=1000000</p>

	<blockquote>
	<p>数量限制，额外的edits事务数。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.max.extra.edits.segments.retained=10000</p>

	<blockquote>
	<p>extra edit日志文件segments的最大数量。除了用于NN重启时的最小edits文件之外。一个segments包含多个日志文件</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.delegation.key.update-interval=86400000</p>

	<blockquote>
	<p>NN中更新主代理令牌的时间间隔，毫秒。安全选项，不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.delegation.token.max-lifetime=604800000</p>

	<blockquote>
	<p>NN中更新主代理令牌的时间间隔，毫秒。安全选项，不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.delegation.token.renew-interval=86400000</p>

	<blockquote>
	<p>NN中更新主代理令牌的时间间隔，毫秒。安全选项，不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.image.compress=FALSE</p>

	<blockquote>
	<p>Image文件要压缩吗？</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.image.compression.codec=org.apache.hadoop.io.compress.DefaultCodec</p>

	<blockquote>
	<p>Image文件压缩编码。必须是在io.compression.codecs中定义的编码。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.image.transfer.timeout=600000</p>

	<blockquote>
	<p>Image文件传输时超时。HA方式使用不到，可不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.image.transfer.bandwidthPerSec=0</p>

	<blockquote>
	<p>Image文件传输时可以使用的最大带宽，秒字节。0表示没有限制。HA方式使用不到，可不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.max.transfer.threads=4096</p>

	<blockquote>
	<p>= 旧参数 dfs.datanode.max.xcievers<br>
	DN上传送数据出入的最大线程数。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.readahead.bytes=4193404</p>

	<blockquote>
	<p>预读磁盘数据。如果Hadoop本地库生效，DN可以调用posix_fadvise系统获取页面数据到操作系统的缓存中。这个配置指定读取当前读取位置之前的字节数。设置为0，取消此功能。无本地库，此功能也无效。？</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.drop.cache.behind.reads=FALSE</p>

	<blockquote>
	<p>在有些场景下，特别是对一些大的，并且不可能重用的数据，缓存在操作系统的缓存区是无用的。此时，DN可以配置自动清理缓存区数据，在已经发生向客户端之后。此功能自动失效，在读取小数据片时。(例如HBase的随机读写场景）。通过释放缓存，这在某些场景下可以提高性能。Hadoop本地库无效，此功能无效。看起来是一个可以尝试的特性</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.drop.cache.behind.writes=FALSE</p>

	<blockquote>
	<p>同dfs.datanode.drop.cache.behind.reads相似。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.sync.behind.writes=FALSE</p>

	<blockquote>
	<p>如果是true，在写之后，DN将指示操作系统把队列中数据全部立即写磁盘。和常用的OS策略不同，它们可能在触发写磁盘之前等待30秒。Hadoop本地库无效，此功能无效。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client.failover.sleep.base.millis=500</p>

	<blockquote>
	<p>专家设置。失败重试间的等待时间，毫秒。这里的值是个基本值，实际值会根据失败/成功次数递增/递减50%。第一次失败会立即重试。第二次将延迟至少dfs.client.failover.sleep.base.millis毫秒。依次类推。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client.failover.sleep.max.millis=15000</p>

	<blockquote>
	<p>专家设置。失败重试见的等待时间最大值，毫秒。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.ha.log-roll.period=120</p>

	<blockquote>
	<p>StandbyNode要求Active滚动EditLog，由于StandBy只能从已经完成的Log Segments中读，所以Standby上的数据新鲜程度依赖于以如何的频率滚动日志。秒。另外，故障转移也会触发一次日志滚动，所以StandbyNode在Active之前，数据也会更新成最新的。秒，默认是2分钟。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.ha.tail-edits.period=60</p>

	<blockquote>
	<p>StandbyNode以此频率检测共享目录中最新的日志，秒。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.ha.zkfc.port=8019</p>

	<blockquote>
	<p>zkfc的rpc端口</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.support.append=TRUE</p>

	<blockquote>
	<p>是否允许append。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client.use.datanode.hostname=FALSE</p>

	<blockquote>
	<p>是否客户端应该使用DN的HostName，在连接DN时，默认是使用IP。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.use.datanode.hostname=FALSE</p>

	<blockquote>
	<p>是否DN应该使用HostName连接其它DN，在数据传输时。默认是是IP。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client.local.interfaces=null</p>

	<blockquote>
	<p>逗号分隔的网卡列表，用于在客户端和DN之间传输数据时。当创建连接时，客户端随机选择一个并绑定它的socket到这个网卡的IP上。名字可以以网卡名(例如 "eth0"), 子网卡名 (eg "eth0:0"), 或者IP地址(which may be specified using CIDR notation to match a range of IPs)。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.kerberos.internal.spnego.principal=${dfs.web.authentication.kerberos.principal}</p>

	<blockquote>
	<p>安全选项，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.secondary.namenode.kerberos.internal.spnego.principal=${dfs.web.authentication.kerberos.principal}</p>

	<blockquote>
	<p>安全选项，暂不关注</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.avoid.read.stale.datanode=FALSE</p>

	<blockquote>
	<p>决定是否避开从脏DN上读数据。脏DN指在一个指定的时间间隔内没有收到心跳信息。脏DN将被移到可以读取节点列表的尾端。尝试开启</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.stale.datanode.interval=30000</p>

	<blockquote>
	<p>标记一个DN是脏的时间间隔。例如，如果NN在此设定的时间内没有接收到来自某一个节点的心跳信息，此DN将被标记为脏的。此间隔不能太小，否则容易导致被频繁的标记为脏DN。</p>

	<blockquote>
	<p><strong>我们建议是1分钟</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.write.stale.datanode.ratio=0.5f</p>

	<blockquote>
	<p>当全部DN被标记为脏DN的比率高于此阀值，停止不写数据到脏DN的策略，以免造成热点问题（有效的，可写的DN太少，压力太大）。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.invalidate.work.pct.per.iteration=0.32f</p>

	<blockquote>
	<p>高级属性。改变需小心。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.namenode.replication.work.multiplier.per.iteration=2</p>

	<blockquote>
	<p>高级属性。改变需小心。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.webhdfs.enabled=FALSE</p>

	<blockquote>
	<p>在NN和DN上开启WebHDFS (REST API)功能。</p>

	<blockquote>
	<p><strong>可以开启尝试</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.fuse.connection.timeout=300</p>

	<blockquote>
	<p>秒，在fuse_dfs中缓存libhdfs连接对象的超时时间。 小值使用内存小。大值可以加快访问，通过避开创建新的连接对象。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>hadoop.fuse.timer.period=5</p>

	<blockquote>
	<p>秒</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.metrics.percentiles.intervals=null</p>

	<blockquote>
	<p>Comma-delimited set of integers denoting the desired rollover intervals (in seconds) for percentile latency metrics on the Namenode and Datanode. By default, percentile latency metrics are disabled.</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.encrypt.data.transfer=FALSE</p>

	<blockquote>
	<p>是否加密传输数据？仅需要配置在NN和DN。客户端可以自行判断。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.encrypt.data.transfer.algorithm=null</p>

	<blockquote>
	<p>可以设置为"3des"或"rc4"。否则使用默认的，通常是usually 3DES。3DES更安全，RC4更快。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.datanode.hdfs-blocks-metadata.enabled=TRUE</p>

	<blockquote>
	<p>布尔值，设定后台DN端是否支持DistributedFileSystem#getFileVBlockStorageLocations API。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client.file-block-storage-locations.num-threads=10</p>

	<blockquote>
	<p>在调用DistributedFileSystem#getFileBlockStorageLocations()的并发RPC的线程数</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.client.file-block-storage-locations.timeout=60</p>

	<blockquote>
	<p>Timeout (in seconds) for the parallel RPCs made in DistributedFileSystem#getFileBlockStorageLocations().</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>dfs.domain.socket.path=/var/run/hadoop-hdfs/dn._PORT</p>

	<blockquote>
	<p>可选选项。socket文件路径，unix下。用来在DN和本地的HDFS客户端加快网络连接。如果字符串"_PORT"出现在路径中，它将被DN的TCP端口替换。</p>
	</blockquote>
	</li>
</ul><h3><a>yarn-default.xml</a></h3>

<ul style="margin-left:20px;"><li style="margin-left:0px;">
	<p>yarn.app.mapreduce.am.env=null</p>

	<blockquote>
	<p>用户为MR AM添加环境变量。例如：</p>

	<ol style="margin-left:20px;"><li style="margin-left:0px;">A=foo 设置环境变量A为foo</li>
		<li style="margin-left:0px;">B=$B:c 继承并设置TT内的B变量</li>
	</ol></blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.app.mapreduce.am.command-opts=-Xmx1024m</strong></p>

	<blockquote>
	<p>MR AM的Java opts。如下符号会被替换：</p>

	<ul style="margin-left:20px;"><li style="margin-left:0px;">@taskid@ 被替换成当前的TaskID。其它出现的'@'不会改变。例如，为了让gc日志能够按task打印存储在/tmp目录，可以设置'value'为：-Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc</li>
		<li style="margin-left:0px;">如果hadoop本地库可以使用，使用-Djava.library.path参数可能造成程序的此功能无效。这个值应该被替换，设置在MR的JVM环境中LD_LIBRARY_PATH变量中，使用 mapreduce.map.env和mapreduce.reduce.env配置项。</li>
	</ul></blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.app.mapreduce.am.resource.mb=1536</strong></p>

	<blockquote>
	<p>AM申请的内存</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.resourcemanager.address=0.0.0.0:8032</strong></p>

	<blockquote>
	<p>RM地址:端口</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.resourcemanager.scheduler.address=0.0.0.0:8030</strong></p>

	<blockquote>
	<p>调度器地址：端口</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.admin.acl=*</strong></p>

	<blockquote>
	<p>ACL中谁可以管理YARN集群</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.resourcemanager.admin.address=0.0.0.0:8033</strong></p>

	<blockquote>
	<p>RM管理接口地址：端口</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.resourcemanager.am.max-retries=1</strong></p>

	<blockquote>
	<p>AM重试最大次数。服务端参数。重启生效。</p>

	<blockquote>
	<p><strong>建议4</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.resourcemanager.nodes.include-path=null</strong></p>

	<blockquote>
	<p>存储有效节点列表的文件</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.resourcemanager.nodes.exclude-path=null</strong></p>

	<blockquote>
	<p>存储拒绝节点列表的文件。如和包含文件冲突，包含文件优先级高</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler</strong></p>

	<blockquote>
	<p>调度器实现类。</p>

	<blockquote>
	<p><strong>建议使用公平调度器</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.scheduler.minimum-allocation-mb=1024</strong></p>

	<blockquote>
	<p>每个container想RM申请内存的最小大小。兆字节。内存请求小于此值，实际申请到的是此值大小。默认值偏大</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.scheduler.maximum-allocation-mb=8192</strong></p>

	<blockquote>
	<p>每个container向RM申请内存的最大大小，兆字节。申请值大于此值，将最多得到此值内存。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.resourcemanager.recovery.enabled=FALSE</strong></p>

	<blockquote>
	<p>是否启动RM的状态恢复功能。如果true，必须指定yarn.resourcemanager.store.class。尝试启用</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.resourcemanager.store.class=null</strong></p>

	<blockquote>
	<p>用于持久存储的类。尝试开启</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.resourcemanager.max-completed-applications=10000</strong></p>

	<blockquote>
	<p>RM中保存的最大完成的app数量。内存中存储。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.address=0.0.0.0:0</strong></p>

	<blockquote>
	<p>NM中的container管理器的地址：端口</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.env-whitelist=JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,YARN_HOME</strong></p>

	<blockquote>
	<p>container应该覆盖而不是使用NM的环境变量名单。允许container自己配置的环境变量</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.delete.debug-delay-sec=0</strong></p>

	<blockquote>
	<p>秒，一个app完成后，NM删除服务将删除app的本地文件目录和日志目录。为了诊断问题，把这个选项设置成足够大的值（例如，设置为10分钟），可以继续访问这些目录。设置此选项，需要重启NM。Yarn应用的工作目录根路径是yarn.nodemanager.local-dirs，Yarn应用日志目录的根路径是yarn.nodemanager.log-dirs。</p>

	<blockquote>
	<p><strong>调试问题时可用</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.local-dirs=${hadoop.tmp.dir}/nm-local-dir</strong></p>

	<blockquote>
	<p>本地文件存储目录，列表。一个应用的本地文件目录定位方式：${yarn.nodemanager.local-dirs}/usercache/${user}/appcache/application_${appid}。每个container的工作目录，是此目录的子目录，目录名是container_${contid}。</p>

	<blockquote>
	<p>非常重要，建议配置多个磁盘，平衡IO。</p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.log-dirs=${yarn.log.dir}/userlogs</strong></p>

	<blockquote>
	<p>存储container日志的地方。一个应用的本地日志目录定位是：${yarn.nodemanager.log-dirs}/application_${appid}。每个container的日志目录在此目录下，名字是container_{$contid}。每个container目录中包含stderr, stdin, and syslog等container产生的文件</p>

	<blockquote>
	<p><strong>非常重要，建议配置多个磁盘</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.log-aggregation-enable=FALSE</strong></p>

	<blockquote>
	<p>是否允许日志汇聚功能。建议开启</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.log-aggregation.retain-seconds=-1</strong></p>

	<blockquote>
	<p>保存汇聚日志时间，秒，超过会删除，-1表示不删除。 注意，设置的过小，将导致NN垃圾碎片。建议3-7天 = 7 * 86400 = 604800</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.log.retain-seconds=10800</strong></p>

	<blockquote>
	<p>保留用户日志的时间，秒。在日志汇聚功能关闭时生效。</p>

	<blockquote>
	<p><strong>建议7天</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.remote-app-log-dir=/tmp/logs</strong></p>

	<blockquote>
	<p>汇聚日志的地方，目录路径，HDFS系统。</p>

	<blockquote>
	<p><strong>对于开了权限检查的系统，注意权限问题。HDFS上。</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.remote-app-log-dir-suffix=logs</strong></p>

	<blockquote>
	<p>汇聚日志目录路径后缀。汇聚目录创建在{yarn.nodemanager.remote-app-log-dir}/${user}/{thisParam}</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.resource.memory-mb=8192</strong></p>

	<blockquote>
	<p>NM上可以用于container申请的物理内存大小，MB。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.vmem-pmem-ratio=2.1</strong></p>

	<blockquote>
	<p>在设置container的内存限制时，虚拟内存到物理内存的比率。Container申请的内存如果超过此物理内存，可以以此比率获取虚拟内存用于满足需求。虚拟地址的是物理地址的倍数上限。建议设置的大点，例如：4.1，8.1，此虚拟内存并非内存，而是占用的虚拟地址。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.webapp.address=0.0.0.0:8042</strong></p>

	<blockquote>
	<p>NM的网页界面地址和端口。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.log-aggregation.compression-type=none</strong></p>

	<blockquote>
	<p>汇聚日志的压缩类型。汇聚日志是TFile格式文件。Hadoop-3315。可以使用的值有none,lzo,gz等。</p>

	<blockquote>
	<p><strong>可以尝试</strong></p>
	</blockquote>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.aux-services=null</strong></p>

	<blockquote>
	<p>请配置为：mapreduce.shuffle，在Yarn上开启MR的必须项</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.nodemanager.aux-services.mapreduce.shuffle.class=org.apache.hadoop.mapred.ShuffleHandler</strong></p>

	<blockquote>
	<p>对应参考yarn.nodemanager.aux-services</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>mapreduce.job.jar=null</strong></p>

	<blockquote>
	<p>Job客户端参数。提交的job的jar文件。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>mapreduce.job.hdfs-servers=${fs.defaultFS}</strong></p>

	<blockquote>
	<p>Job客户端参数。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p><strong>yarn.application.classpath=$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/share/hadoop/common/,$HADOOP_COMMON_HOME/share/hadoop/common/lib/,$HADOOP_HDFS_HOME/share/hadoop/hdfs/,$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/,$YARN_HOME/share/hadoop/yarn/*,$YARN_HOME/share/hadoop/yarn/lib/*</strong></p>

	<blockquote>
	<p>YARN应用的CLASSPATH，逗号分隔列表。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.app.mapreduce.am.job.task.listener.thread-count=30</p>

	<blockquote>
	<p>MR AM处理RPC调用的线程数。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.app.mapreduce.am.job.client.port-range=null</p>

	<blockquote>
	<p>MR AM能够绑定使用的端口范围。例如：50000-50050,50100-50200。 如果你先要全部的有用端口，可以留空（默认值null）。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.app.mapreduce.am.job.committer.cancel-timeout=60000</p>

	<blockquote>
	<p>毫秒，如果job被kill了，等待output committer取消操作的时间。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms=1000</p>

	<blockquote>
	<p>MR AM发送心跳到RM的时间间隔，毫秒</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.app.mapreduce.client-am.ipc.max-retries=3</p>

	<blockquote>
	<p>在重新连接RM获取Application状态前，客户端重试连接AM的次数。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.app.mapreduce.client.max-retries=3</p>

	<blockquote>
	<p>客户端重连RM/HS/AM的次数。这是基于ipc接口上的规则</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.ipc.client.factory.class=null</p>

	<blockquote>
	<p>创建客户端IPC类的工厂类</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.ipc.serializer.type=protocolbuffers</p>

	<blockquote>
	<p>使用哪种序列化类</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.ipc.server.factory.class=null</p>

	<blockquote>
	<p>创建IPC服务类的工厂类</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.ipc.exception.factory.class=null</p>

	<blockquote>
	<p>创建IPC异常的工厂类</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.ipc.record.factory.class=null</p>

	<blockquote>
	<p>创建序列化记录的工厂类</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.ipc.rpc.class=org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC</p>

	<blockquote>
	<p>RPC类实现类</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.client.thread-count=50</p>

	<blockquote>
	<p>RM用来处理客户端请求的线程数</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.am.liveness-monitor.expiry-interval-ms=600000</p>

	<blockquote>
	<p>AM报告间隔，毫秒。？</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.principal=null</p>

	<blockquote>
	<p>安全选项</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.scheduler.client.thread-count=50</p>

	<blockquote>
	<p>调度器用于处理请求的线程数</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.webapp.address=0.0.0.0:8088</p>

	<blockquote>
	<p>RM的网页接口地址：端口</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.resource-tracker.address=0.0.0.0:8031</p>

	<blockquote>
	<p>？</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.acl.enable=TRUE</p>

	<blockquote>
	<p>开启访问控制</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.admin.client.thread-count=1</p>

	<blockquote>
	<p>RM管理端口处理事务的线程数</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.amliveliness-monitor.interval-ms=1000</p>

	<blockquote>
	<p>RM检查AM存活的间隔</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.container.liveness-monitor.interval-ms=600000</p>

	<blockquote>
	<p>检查container存活的时间间隔，毫秒。建议短一些，例如3分钟</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.keytab=/etc/krb5.keytab</p>

	<blockquote>
	<p>安全选项</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.nm.liveness-monitor.expiry-interval-ms=600000</p>

	<blockquote>
	<p>RM判断NM死亡的时间间隔。<br>
	非主动检查，被动等待，不连接时间超过此值<br>
	10分钟无检查到活动，判定NM死亡</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.nm.liveness-monitor.interval-ms=1000</p>

	<blockquote>
	<p>RM检查NM存活的时间间隔。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.resource-tracker.client.thread-count=50</p>

	<blockquote>
	<p>处理资源跟踪调用的线程数。？</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.delayed.delegation-token.removal-interval-ms=30000</p>

	<blockquote>
	<p>安全选项</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.application-tokens.master-key-rolling-interval-secs=86400</p>

	<blockquote>
	<p>安全选项</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs=86400</p>

	<blockquote>
	<p>安全选项</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.nodemanager.admin-env=MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX</p>

	<blockquote>
	<p>应该从NM传送到container的环境变量</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.nodemanager.container-executor.class=org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</p>

	<blockquote>
	<p>启动containers的类。</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.nodemanager.container-manager.thread-count=20</p>

	<blockquote>
	<p>用于container管理的线程数</p>
	</blockquote>
	</li>
	<li style="margin-left:0px;">
	<p>yarn.nodemanager.delete.thread-count=4</p>
	</li>
</ul>            </div>
                </div>