---
layout:     post
title:      hdfs-命令总结
---
<div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">
								            <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f76675cdea.css">
						<div class="htmledit_views" id="content_views">
                hdfs 命令：<br>hdfs dfs -ls  / 列出根目文件<br><br>hdfs dfs -ls -R / 列出文件系统的文件路径<br><br>hadoop fs -put &lt; local file &gt; &lt; hdfs file &gt;<br>hdfs file的父目录一定要存在，否则命令不会执行<br><br>hadoop fs -put  &lt; local file or dir &gt;...&lt; hdfs dir &gt;<br>hdfs dir 一定要存在，否则命令不会执行<br><br>hadoop fs -put - &lt; hdsf  file&gt;<br>从键盘读取输入到hdfs file中，按Ctrl+D结束输入，hdfs file不能存在，否则命令不会执行<br><br>hadoop fs -moveFromLocal  &lt; local src &gt; ... &lt; hdfs dst &gt;<br>与put相类似，命令执行后源文件 local src 被删除，也可以从从键盘读取输入到hdfs file中<br><br>hadoop fs -copyFromLocal  &lt; local src &gt; ... &lt; hdfs dst &gt;<br>与put相类似，也可以从从键盘读取输入到hdfs file中<br><br>hadoop fs -get &lt; hdfs file &gt; &lt; local file or dir&gt;<br>local file不能和 hdfs file名字不能相同，否则会提示文件已存在，没有重名的文件会复制到本地<br><br>hadoop fs -get &lt; hdfs file or dir &gt; ... &lt; local  dir &gt;<br>拷贝多个文件或目录到本地时，本地要为文件夹路径<br>注意：如果用户不是root， local 路径要为用户文件夹下的路径，否则会出现权限问题，<br><br>hadoop fs -copyToLocal &lt; local src &gt; ... &lt; hdfs dst &gt;<br>与get相类似<br><br>hadoop fs -rm &lt; hdfs file &gt; ...<br>hadoop fs -rm -r &lt; hdfs dir&gt;...<br>每次可以删除多个文件或目录<br><br>hadoop fs -mkdir &lt; hdfs path&gt;<br>只能一级一级的建目录，父目录不存在的话使用这个命令会报错<br><br>hadoop fs -mkdir -p &lt; hdfs path&gt; <br>所创建的目录如果父目录不存在就创建该父目录<br><br>hadoop fs -getmerge &lt; hdfs dir &gt;  &lt; local file &gt;<br>将hdfs指定目录下所有文件排序后合并到local指定的文件中，文件不存在时会自动创建，文件存在时会覆盖里面的内容<br><br>hadoop fs -getmerge -nl  &lt; hdfs dir &gt;  &lt; local file &gt;<br>加上nl后，合并到local file中的hdfs文件之间会空出一行<br><br>hadoop fs -cp  &lt; hdfs file &gt;  &lt; hdfs file &gt;<br>目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件还存在<br><br>hadoop fs -cp &lt; hdfs file or dir &gt;... &lt; hdfs dir &gt;<br>目标文件夹要存在，否则命令不能执行<br><br>hadoop fs -mv &lt; hdfs file &gt;  &lt; hdfs file &gt;<br>目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件不存在<br><br>hadoop fs -mv  &lt; hdfs file or dir &gt;...  &lt; hdfs dir &gt;<br>源路径有多个时，目标路径必须为目录，且必须存在。<br>注意：跨文件系统的移动（local到hdfs或者反过来）都是不允许的<br><br>hadoop fs -count &lt; hdfs path &gt;<br>统计hdfs对应路径下的目录个数，文件个数，文件总计大小<br>显示为目录个数，文件个数，文件总计大小，输入路径<br><br>hadoop fs -du &lt; hdsf path&gt; <br>显示hdfs对应路径下每个文件夹和文件的大小<br><br>hadoop fs -du -s &lt; hdsf path&gt; <br>显示hdfs对应路径下所有文件和的大小<br><br>hadoop fs -du - h &lt; hdsf path&gt; <br>显示hdfs对应路径下每个文件夹和文件的大小,文件的大小用方便阅读的形式表示，例如用64M代替67108864<br><br>hadoop fs -text &lt; hdsf file&gt;<br>将文本文件或某些格式的非文本文件通过文本格式输出<br><br>hadoop fs -setrep -R 3 &lt; hdfs path &gt;<br>改变一个文件在hdfs中的副本个数，上述命令中数字3为所设置的副本个数，-R选项可以对一个人目录下的所有目录+文件递归执行改变副本个数的操作<br><br>hdoop fs -stat [format] &lt; hdfs path &gt;<br>返回对应路径的状态信息<br>[format]可选参数有：%b（文件大小），%o（Block大小），%n（文件名），%r（副本个数），%y（最后一次修改日期和时间）<br>可以这样书写hadoop fs -stat %b%o%n &lt; hdfs path &gt;，不过不建议，这样每个字符输出的结果不是太容易分清楚<br><br>hadoop fs -tail &lt; hdfs file &gt;<br>在标准输出中显示文件末尾的1KB数据<br><br>hadoop archive -archiveName name.har -p &lt; hdfs parent dir &gt; &lt; src &gt;* &lt; hdfs dst &gt;<br>命令中参数name：压缩文件名，自己任意取；&lt; hdfs parent dir &gt; ：压缩文件所在的父目录；&lt; src &gt;：要压缩的文件名；&lt; hdfs dst &gt;：压缩文件存放路径<br>*示例：hadoop archive -archiveName hadoop.har -p /user 1.txt 2.txt /des<br>示例中将hdfs中/user目录下的文件1.txt，2.txt压缩成一个名叫hadoop.har的文件存放在hdfs中/des目录下，如果1.txt，2.txt不写就是将/user目录下所有的目录和文件压缩成一个名叫hadoop.har的文件存放在hdfs中/des目录下<br>显示har的内容可以用如下命令：<br><br>hadoop fs -ls /des/hadoop.jar<br><br>显示har压缩的是那些文件可以用如下命令<br><br>hadoop fs -ls -R har:///des/hadoop.har<br>注意：har文件不能进行二次压缩。如果想给.har加文件，只能找到原来的文件，重新创建一个。har文件中原来文件的数据并没有变化，har文件真正的作用是减少NameNode和DataNode过多的空间浪费。<br><br>hdfs balancer<br>如果管理员发现某些DataNode保存数据过多，某些DataNode保存数据相对较少，可以使用上述命令手动启动内部的均衡过程<br><br>hdfs dfsadmin -help<br>管理员可以通过dfsadmin管理HDFS，用法可以通过上述命令查看<br><br>hdfs dfsadmin -report<br>显示文件系统的基本数据<br><br>hdfs dfsadmin -safemode &lt; enter | leave | get | wait &gt;<br>enter：进入安全模式；leave：离开安全模式；get：获知是否开启安全模式；<br>wait：等待离开安全模式<br><br>distcp<br>用来在两个HDFS之间拷贝数据<br><br>            </div>
                </div>